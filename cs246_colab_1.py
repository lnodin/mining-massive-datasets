# -*- coding: utf-8 -*-
"""CS246 - Colab 1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/github/nhutnamhcmus/mining-massive-datasets/blob/main/CS246_Colab_1.ipynb

# CS246 - Colab 1
## Wordcount in Spark

### Setup

Let's setup Spark on your Colab environment.  Run the cell below!
"""

!pip install pyspark
!pip install -U -q PyDrive
!apt install openjdk-8-jdk-headless -qq
import os
os.environ["JAVA_HOME"] = "/usr/lib/jvm/java-8-openjdk-amd64"

"""Now we authenticate a Google Drive client to download the file we will be processing in our Spark job.

**Make sure to follow the interactive instructions.**
"""

from pydrive.auth import GoogleAuth
from pydrive.drive import GoogleDrive
from google.colab import auth
from oauth2client.client import GoogleCredentials

# Authenticate and create the PyDrive client
auth.authenticate_user()
gauth = GoogleAuth()
gauth.credentials = GoogleCredentials.get_application_default()
drive = GoogleDrive(gauth)

id='1SE6k_0YukzGd5wK-E4i6mG83nydlfvSa'
downloaded = drive.CreateFile({'id': id})
downloaded.GetContentFile('pg100.txt')

"""If you executed the cells above, you should be able to see the file *pg100.txt* under the "Files" tab on the left panel.

### Your task

If you run successfully the setup stage, you are ready to work on the *pg100.txt* file which contains a copy of the complete works of Shakespeare.

Write a Spark application which outputs the number of words that start with each letter. This means that for every letter we want to count the total number of (non-unique) words that start with a specific letter. In your implementation **ignore the letter case**, i.e., consider all words as lower case. Also, you can ignore all the words **starting** with a non-alphabetic character.
"""

from pyspark.sql import *
from pyspark.sql.functions import *
from pyspark import SparkContext
import pandas as pd

# create the Spark Session
spark = SparkSession.builder.getOrCreate()

# create the Spark Context
sc = spark.sparkContext

# YOUR
txt = sc.textFile('pg100.txt')
txt.take(10)

# CODE
wordRdd = txt.map(lambda x: x.lower()).flatMap(lambda x: x.split(' '))
wordRdd.take(10)

# HERE
import pandas as pd
df = pd.DataFrame()
df['char'] = [chr(i) for i in range(ord('a'), ord('z') + 1)]
df.head()

def counting(char):
  return wordRdd.filter(lambda x: x[0] in {char} if x else False).count()

df['count'] = df['char'].apply(counting)
df.head()

ax = df.plot(kind='bar', x='char', y='count', figsize=(12, 8), alpha=0.5,)
for p in ax.patches:
    ax.annotate(str(p.get_height()), (p.get_x() * 1.005, p.get_height() * 1.005))

"""Once you obtained the desired results, **head over to Gradescope and submit your solution for this Colab**!"""