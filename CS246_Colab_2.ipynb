{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CS246 - Colab 2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kPt5q27L5557"
      },
      "source": [
        "# CS246 - Colab 2\n",
        "## Frequent Pattern Mining in Spark"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p0-YhEpP_Ds-"
      },
      "source": [
        "### Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zsj5WYpR9QId"
      },
      "source": [
        "Let's setup Spark on your Colab environment.  Run the cell below!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k-qHai2252mI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bba6031e-eb0f-4b93-f3ad-b33ddb39bf17"
      },
      "source": [
        "!pip install pyspark\n",
        "!pip install -U -q PyDrive\n",
        "!apt install openjdk-8-jdk-headless -qq\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\""
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyspark\n",
            "  Downloading pyspark-3.1.2.tar.gz (212.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 212.4 MB 71 kB/s \n",
            "\u001b[?25hCollecting py4j==0.10.9\n",
            "  Downloading py4j-0.10.9-py2.py3-none-any.whl (198 kB)\n",
            "\u001b[K     |████████████████████████████████| 198 kB 44.7 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.1.2-py2.py3-none-any.whl size=212880768 sha256=7a09df8b70796788e31793da16726d13954711cfc2a71681c50b63309a124239\n",
            "  Stored in directory: /root/.cache/pip/wheels/a5/0a/c1/9561f6fecb759579a7d863dcd846daaa95f598744e71b02c77\n",
            "Successfully built pyspark\n",
            "Installing collected packages: py4j, pyspark\n",
            "Successfully installed py4j-0.10.9 pyspark-3.1.2\n",
            "The following additional packages will be installed:\n",
            "  openjdk-8-jre-headless\n",
            "Suggested packages:\n",
            "  openjdk-8-demo openjdk-8-source libnss-mdns fonts-dejavu-extra\n",
            "  fonts-ipafont-gothic fonts-ipafont-mincho fonts-wqy-microhei\n",
            "  fonts-wqy-zenhei fonts-indic\n",
            "The following NEW packages will be installed:\n",
            "  openjdk-8-jdk-headless openjdk-8-jre-headless\n",
            "0 upgraded, 2 newly installed, 0 to remove and 37 not upgraded.\n",
            "Need to get 36.5 MB of archives.\n",
            "After this operation, 143 MB of additional disk space will be used.\n",
            "Selecting previously unselected package openjdk-8-jre-headless:amd64.\n",
            "(Reading database ... 155013 files and directories currently installed.)\n",
            "Preparing to unpack .../openjdk-8-jre-headless_8u292-b10-0ubuntu1~18.04_amd64.deb ...\n",
            "Unpacking openjdk-8-jre-headless:amd64 (8u292-b10-0ubuntu1~18.04) ...\n",
            "Selecting previously unselected package openjdk-8-jdk-headless:amd64.\n",
            "Preparing to unpack .../openjdk-8-jdk-headless_8u292-b10-0ubuntu1~18.04_amd64.deb ...\n",
            "Unpacking openjdk-8-jdk-headless:amd64 (8u292-b10-0ubuntu1~18.04) ...\n",
            "Setting up openjdk-8-jre-headless:amd64 (8u292-b10-0ubuntu1~18.04) ...\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/orbd to provide /usr/bin/orbd (orbd) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/servertool to provide /usr/bin/servertool (servertool) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/tnameserv to provide /usr/bin/tnameserv (tnameserv) in auto mode\n",
            "Setting up openjdk-8-jdk-headless:amd64 (8u292-b10-0ubuntu1~18.04) ...\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/idlj to provide /usr/bin/idlj (idlj) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/wsimport to provide /usr/bin/wsimport (wsimport) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/jsadebugd to provide /usr/bin/jsadebugd (jsadebugd) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/native2ascii to provide /usr/bin/native2ascii (native2ascii) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/javah to provide /usr/bin/javah (javah) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/hsdb to provide /usr/bin/hsdb (hsdb) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/clhsdb to provide /usr/bin/clhsdb (clhsdb) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/extcheck to provide /usr/bin/extcheck (extcheck) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/schemagen to provide /usr/bin/schemagen (schemagen) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/xjc to provide /usr/bin/xjc (xjc) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/jhat to provide /usr/bin/jhat (jhat) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/wsgen to provide /usr/bin/wsgen (wsgen) in auto mode\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-CJ71AKe91eh"
      },
      "source": [
        "Now we authenticate a Google Drive client to download the file we will be processing in our Spark job.\n",
        "\n",
        "**Make sure to follow the interactive instructions.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5K93ABEy9Zlo"
      },
      "source": [
        "# Import pydrive for login Google Cloud SDK\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "# Authenticate and create the PyDrive client\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0orRvrc1-545"
      },
      "source": [
        "# Download file products.csv\n",
        "id='1dhi1F78ssqR8gE6U-AgB80ZW7V_9snX4'\n",
        "downloaded = drive.CreateFile({'id': id})\n",
        "downloaded.GetContentFile('products.csv')\n",
        "\n",
        "# Download file order_products__train.csv\n",
        "id='1KZBNEaIyMTcsRV817us6uLZgm-Mii8oU'\n",
        "downloaded = drive.CreateFile({'id': id})\n",
        "downloaded.GetContentFile('order_products__train.csv')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qwtlO4_m_LbQ"
      },
      "source": [
        "If you executed the cells above, you should be able to see the dataset we will need for this Colab under the \"Files\" tab on the left panel."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "twk-K-jilWK7"
      },
      "source": [
        "# Import lib for table data processing\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "# Import PySpark\n",
        "import pyspark\n",
        "from pyspark.sql import *\n",
        "from pyspark.sql.functions import *\n",
        "from pyspark import SparkContext, SparkConf"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dr-8fK-1lmY0"
      },
      "source": [
        "Let's initialize the Spark context."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UOwtm2l7lePt"
      },
      "source": [
        "# create the session\n",
        "conf = SparkConf().set(\"spark.ui.port\", \"4050\")\n",
        "\n",
        "# create the context\n",
        "sc = pyspark.SparkContext(conf=conf)\n",
        "spark = SparkSession.builder.getOrCreate()"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s-LpyCLzlul6"
      },
      "source": [
        "You can easily check the current version and get the link of the web interface. In the Spark UI, you can monitor the progress of your job and debug the performance bottlenecks (if your Colab is running with a **local runtime**)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0g87iz4klwYJ",
        "outputId": "60efddeb-86b9-497e-8e69-0a153dae3908",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 222
        }
      },
      "source": [
        "spark"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://e9fa44d8c2f6:4050\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.1.2</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>pyspark-shell</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ],
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x7f328402f710>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vdwc4xKPl3Jv"
      },
      "source": [
        "If you are running this Colab on the Google hosted runtime, the cell below will create a *ngrok* tunnel which will allow you to still check the Spark UI."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qephEB4Tl14J",
        "outputId": "3ce3b221-01a1-4f3f-df26-55e5c4d5960f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
        "!unzip ngrok-stable-linux-amd64.zip\n",
        "get_ipython().system_raw('./ngrok http 4050 &')\n",
        "!curl -s http://localhost:4040/api/tunnels | python3 -c \\\n",
        "    \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\""
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-09-27 05:29:32--  https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
            "Resolving bin.equinox.io (bin.equinox.io)... 52.202.168.65, 18.205.222.128, 54.237.133.81, ...\n",
            "Connecting to bin.equinox.io (bin.equinox.io)|52.202.168.65|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 13832437 (13M) [application/octet-stream]\n",
            "Saving to: ‘ngrok-stable-linux-amd64.zip’\n",
            "\n",
            "ngrok-stable-linux- 100%[===================>]  13.19M  6.07MB/s    in 2.2s    \n",
            "\n",
            "2021-09-27 05:29:35 (6.07 MB/s) - ‘ngrok-stable-linux-amd64.zip’ saved [13832437/13832437]\n",
            "\n",
            "Archive:  ngrok-stable-linux-amd64.zip\n",
            "  inflating: ngrok                   \n",
            "Traceback (most recent call last):\n",
            "  File \"<string>\", line 1, in <module>\n",
            "IndexError: list index out of range\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CRaF2A_j_nC7"
      },
      "source": [
        "### Your task"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ebLNUxP0_8x3"
      },
      "source": [
        "If you run successfully the setup stage, you are ready to work with the **3 Million Instacart Orders** dataset. In case you want to read more about it, check the [official Instacart blog post](https://tech.instacart.com/3-million-instacart-orders-open-sourced-d40d29ead6f2) about it, a concise [schema description](https://gist.github.com/jeremystan/c3b39d947d9b88b3ccff3147dbcf6c6b) of the dataset, and the [download page](https://www.instacart.com/datasets/grocery-shopping-2017).\n",
        "\n",
        "In this Colab, we will be working only with a small training dataset (~131K orders) to perform fast Frequent Pattern Mining with the FP-Growth algorithm."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xu-e7Ph2_ruG"
      },
      "source": [
        "products = spark.read.csv('products.csv', header=True, inferSchema=True)\n",
        "orders = spark.read.csv('order_products__train.csv', header=True, inferSchema=True)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hhxZZRT9syUO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f12fce76-fe6f-4228-dd73-073d42f43eed"
      },
      "source": [
        "products.printSchema()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- product_id: integer (nullable = true)\n",
            " |-- product_name: string (nullable = true)\n",
            " |-- aisle_id: string (nullable = true)\n",
            " |-- department_id: string (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8VeRYRz2s1pm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1ac68c7f-b5f4-4844-dbd7-7e665a2e01d4"
      },
      "source": [
        "orders.printSchema()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- order_id: integer (nullable = true)\n",
            " |-- product_id: integer (nullable = true)\n",
            " |-- add_to_cart_order: integer (nullable = true)\n",
            " |-- reordered: integer (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h5muD_Io59CG"
      },
      "source": [
        "Use the Spark Dataframe API to join 'products' and 'orders', so that you will be able to see the product names in each transaction (and not only their ids).  Then, group by the orders by 'order_id' to obtain one row per basket (i.e., set of products purchased together by one customer). "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zRH4o4p7s7V6",
        "outputId": "c3f160b8-b20b-4ffc-f8e1-4facc6b215e0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# YOUR CODE HERE\n",
        "transactions = orders.join(products, on='product_id').groupby('order_id').agg(collect_list('product_name').alias('product_names'))\n",
        "transactions.take(10)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Row(order_id=1342, product_names=['Bag of Organic Bananas', 'Seedless Cucumbers', 'Organic Mandarins', 'Organic Strawberries', 'Versatile Stain Remover', 'Pink Lady Apples', 'Chicken Apple Sausage', 'Raw Shrimp']),\n",
              " Row(order_id=1591, product_names=['Cracked Wheat', 'Organic Greek Whole Milk Blended Vanilla Bean Yogurt', 'Navel Oranges', 'Spinach', 'Original Patties (100965) 12 Oz Breakfast', 'Cinnamon Multigrain Cereal', 'Chewy 25% Low Sugar Chocolate Chip Granola', 'Uncured Genoa Salami', 'Natural Vanilla Ice Cream', 'Lemon Yogurt', 'Strawberry Rhubarb Yoghurt', 'Garlic', 'Pure Vanilla Extract', 'Lower Sugar Instant Oatmeal  Variety', 'Organic Bunny Fruit Snacks Berry Patch', 'Buttermilk Waffles', 'Granny Smith Apples', 'Medium Scarlet Raspberries', 'Banana', 'Strawberry Banana Smoothie', 'Green Machine Juice Smoothie', 'Ultra Thin Sliced Provolone Cheese', 'Oven Roasted Turkey Breast', 'Original Turkey Burgers Smoke Flavor Added', 'Original Whole Grain Chips', 'Goldfish Pretzel Baked Snack Crackers', 'Twisted Tropical Tango Organic Juice Drink', 'Goodness Grapeness Organic Juice Drink', 'Nutty Bars', 'Honey Graham Snacks', 'Coconut Dreams Cookies']),\n",
              " Row(order_id=4519, product_names=['Beet Apple Carrot Lemon Ginger Organic Cold Pressed Juice Beverage']),\n",
              " Row(order_id=4935, product_names=['Vodka']),\n",
              " Row(order_id=6357, product_names=['Fresh Mozzarella Ball', 'Grated Parmesan', 'Organic Basil', 'Provolone', 'Gala Apples', 'Panko Bread Crumbs', 'Italian Pasta Sauce Basilico Tomato, Basil & Garlic', 'Globe Eggplant', 'Banana']),\n",
              " Row(order_id=10362, product_names=['Crinkle Cut French Fries', 'The Ultimate Beefless Burger', 'Original Tofurky Deli Slices', \"Slow Roasted Lightly Seasoned Chick'n\", 'Organic Gala Apples', 'Hass Avocados', 'Organic Baby Spinach', 'Bag of Organic Bananas', 'Organic Basil', 'Jalapeno Peppers', 'Organic Leek', 'Lemons', 'Limes', 'Organic Red Bell Pepper', 'Roma Tomato', 'Organic Shredded Carrots', 'Yellow Bell Pepper', 'Organic Spring Mix', 'Organic Garnet Sweet Potato (Yam)', 'Large Greenhouse Tomato', 'Sliced Baby Bella Mushrooms', 'Organic Whole Cashews', 'Coconut Flour', 'Pitted Dates', 'Light Brown Sugar', 'Extra Virgin Olive Oil', 'Organic Tapioca Flour', 'Organic Coconut Milk', 'Organic Harissa Seasoning', 'Crushed Garlic', 'Multigrain Tortilla Chips', 'Organic Pinto Beans', 'Organic Shredded Mild Cheddar', 'Organic Three Grain Tempeh', 'Organic Extra Firm Tofu', 'Ground Sausage Style Veggie Protein']),\n",
              " Row(order_id=19204, product_names=['Lemon Lime Thirst Quencher', 'Electrolyte Enhanced Water', 'High Efficiency Complete Dual Formula', 'Cinnamon Cereal', 'Reduced Fat Crackers', 'Mozzarella String Cheese Sticks, Light Low-Moisture Part Skim', 'Peanut Powder', 'Reduced Fat Creamy Peanut Butter Spread', 'Dishwasher Cleaner', 'Fat Free & Lower Sodium Chicken Broth', 'American Blend Salad', 'Disinfecting Wipes Lemon & Fresh Scent', 'Original Petroleum Jelly', 'Extra Nasal Strips']),\n",
              " Row(order_id=29601, product_names=['Toasted Coconut Almondmilk Blend', 'Skillet Refried Red Beans Sautéed With Onion & Tomatillo', 'Organic Greek Lowfat Yogurt With Strawberries', 'Unsweetened Whole Milk Peach Greek Yogurt', 'Small Batch Authentic Taqueria Tortilla Chips', 'SALSA        FRNTR CHPTL SALSA', 'Tomatillo Salsa', 'Guacamole', 'Organic Red Onion', 'Bag of Organic Bananas', 'Banana Chia Pod', 'Mini Whole Wheat Pita Bread', 'Hummus, Hope, Original Recipe', 'Water', 'Coconut Almond Creamer Blend', 'Almondmilk, Pure, Chocolate Protein', 'California Orange Juice']),\n",
              " Row(order_id=31035, product_names=['Bag of Organic Bananas', 'Organic Navel Orange', 'Organic Cripps Pink Apples', 'Organic Golden Delicious Apple']),\n",
              " Row(order_id=40011, product_names=['Sea Salt Macadamias', 'Natural Calm Magnesium Supplement Raspberry Lemon Flavor Powder', 'Organic Baby Spinach', 'Chocolate Coconut Protein Bar', 'Sport Chocolate Mint Protein Bar', 'Organic Blues Bread with Blue Cornmeal Crust'])]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Zu2OTHxvE6R",
        "outputId": "7bbcb725-b940-4aa6-b679-93d1912b39f5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "transactions.show()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+--------------------+\n",
            "|order_id|       product_names|\n",
            "+--------+--------------------+\n",
            "|    1342|[Bag of Organic B...|\n",
            "|    1591|[Cracked Wheat, O...|\n",
            "|    4519|[Beet Apple Carro...|\n",
            "|    4935|             [Vodka]|\n",
            "|    6357|[Fresh Mozzarella...|\n",
            "|   10362|[Crinkle Cut Fren...|\n",
            "|   19204|[Lemon Lime Thirs...|\n",
            "|   29601|[Toasted Coconut ...|\n",
            "|   31035|[Bag of Organic B...|\n",
            "|   40011|[Sea Salt Macadam...|\n",
            "|   46266|[Organic Uncured ...|\n",
            "|   51607|[Major Dickason's...|\n",
            "|   58797|[Bag of Organic B...|\n",
            "|   61793|[Raspberries, Nat...|\n",
            "|   67089|[Banana, Organic ...|\n",
            "|   70863|[Bathroom Tissue,...|\n",
            "|   88674|[Unsweetened Almo...|\n",
            "|   91937|[No. 485 Gin, Tra...|\n",
            "|   92317|[Banana, Indian M...|\n",
            "|   99621|[Organic Basil, F...|\n",
            "+--------+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EfHoTLAg6qnM"
      },
      "source": [
        "In this Colab we will explore [MLlib](https://spark.apache.org/mllib/), Apache Spark's scalable machine learning library. Specifically, you can use its implementation of the [FP-Growth](https://spark.apache.org/docs/latest/ml-frequent-pattern-mining.html#fp-growth) algorithm to perform efficiently Frequent Pattern Mining in Spark.\n",
        "Use the Python example in the documentation, and train a model with \n",
        "\n",
        "```minSupport=0.01``` and ```minConfidence=0.5```\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "boWgxXNns089"
      },
      "source": [
        "# YOUR CODE HERE\n",
        "from pyspark.ml.fpm import FPGrowth\n",
        "\n",
        "# Hyperparameter\n",
        "minSupport=0.01\n",
        "minConfidence=0.5\n",
        "\n",
        "# Initthe FP-Growth algorithm \n",
        "fpGrowth = FPGrowth(itemsCol=\"product_names\", minSupport=minSupport, minConfidence=minConfidence)\n",
        "\n",
        "# Fitting model\n",
        "model = fpGrowth.fit(transactions)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6kpTVdfD8UiO"
      },
      "source": [
        "Compute how many frequent itemsets and association rules were generated by running FP-growth.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6KYgQ_URunvA",
        "outputId": "5ff1960a-e4d2-47c2-dd21-13dd767ee487",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# YOUR CODE HERE\n",
        "model.freqItemsets.show()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+-----+\n",
            "|               items| freq|\n",
            "+--------------------+-----+\n",
            "|            [Banana]|18726|\n",
            "|[Bag of Organic B...|15480|\n",
            "|[Organic Strawber...|10894|\n",
            "|[Organic Strawber...| 3074|\n",
            "|[Organic Strawber...| 2174|\n",
            "|[Organic Baby Spi...| 9784|\n",
            "|[Organic Baby Spi...| 1639|\n",
            "|[Organic Baby Spi...| 2236|\n",
            "|[Organic Baby Spi...| 2000|\n",
            "|       [Large Lemon]| 8135|\n",
            "|[Large Lemon, Ban...| 2158|\n",
            "|   [Organic Avocado]| 7409|\n",
            "|[Organic Avocado,...| 1349|\n",
            "|[Organic Avocado,...| 1402|\n",
            "|[Organic Avocado,...| 2216|\n",
            "|[Organic Hass Avo...| 7293|\n",
            "|[Organic Hass Avo...| 1539|\n",
            "|[Organic Hass Avo...| 2420|\n",
            "|      [Strawberries]| 6494|\n",
            "|[Strawberries, Ba...| 1948|\n",
            "+--------------------+-----+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HJe9ejDBwBNa",
        "outputId": "f6e3ede8-37d5-4def-885d-96de3222cc78",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model.associationRules.show()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+----------+----------+----+-------+\n",
            "|antecedent|consequent|confidence|lift|support|\n",
            "+----------+----------+----------+----+-------+\n",
            "+----------+----------+----------+----+-------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xc7_LSnewY_H",
        "outputId": "89c1ac57-adb0-4d7a-d9f0-4a60067ed4ec",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(\"Couting Frequent Itemsets: {}\".format(model.freqItemsets.count()))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Couting Frequent Itemsets: 120\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GnMMxd8vwlU1",
        "outputId": "4b260d1f-fc7b-4d7a-f08a-81dd09e144c4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(\"Couting Association Rules: {}\".format(model.associationRules.count()))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Couting Association Rules: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qT8Lwm1VAPoN"
      },
      "source": [
        "Now retrain the FP-growth model changing only \n",
        "```minsupport=0.001``` \n",
        "and compute how many frequent itemsets and association rules were generated.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F4LTM9beApYn"
      },
      "source": [
        "# YOUR CODE HERE\n",
        "\n",
        "# Hyperparameter\n",
        "newMinSupport=0.001\n",
        "\n",
        "# Initthe FP-Growth algorithm \n",
        "fpGrowth = FPGrowth(itemsCol=\"product_names\", minSupport=newMinSupport, minConfidence=minConfidence)\n",
        "\n",
        "# Fitting model\n",
        "model = fpGrowth.fit(transactions)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RTXpBOWow_GF",
        "outputId": "1ffdf3c1-9037-4e7d-dda1-b80b2aa62d0a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(\"Couting Frequent Itemsets: {}\".format(model.freqItemsets.count()))\n",
        "print(\"Couting Association Rules: {}\".format(model.associationRules.count()))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Couting Frequent Itemsets: 4444\n",
            "Couting Association Rules: 11\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k9FOt5jRNFGt"
      },
      "source": [
        "To conclude, go to Gradescope and read the remaining questions. We will ask you to inspect the resulting dataframes, and report a few results.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wEqWxzTCNS87"
      },
      "source": [
        "# YOUR CODE HERE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2WSXPflUN76-"
      },
      "source": [
        "Once you obtained the desired results, **head over to Gradescope and submit your solution for this Colab**!"
      ]
    }
  ]
}